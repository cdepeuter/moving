{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving to the big apple\n",
    "\n",
    "In September I began a Masters program in Data Science in New York City. Moving from Hartford, CT I was not really prepared for the New York housing market, despite many warnings from friends. I also did not take as much time off as I should have leaving my previous job, and this led me to some laziness when approaching the apartment search. The main issue in the New York housing market is that places come and go so quickly. If a place is any good, it will probably be off the market in a few days. After realizing this I wanted to be the first to know when something opened up, but I didn't want to have to sit on a computer and watch.\n",
    "\n",
    "\n",
    "## The code\n",
    "\n",
    "First, I'll need to scrape the places from streetEasy. In addition to all of major information someone looks for in an apartment such as price, size, neighborhood, the most important piece of information for me is how far the apartment is from Columbia, so first I'll write a function which uses the geopy library to tell me that.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from geopy.distance import vincenty\n",
    "\n",
    "\n",
    "def getDistFromColumbia(coords):\n",
    "    #given a set of coordinates, how far in miles is that location from Columbia\n",
    "    columbia = (40.807511,-73.9647077)\n",
    "    dist = vincenty(columbia, coords.split(\",\")).miles\n",
    "    \n",
    "    return dist\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I'll build the main scraping function which gets me all of the information I want, including distance from Columbia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def getPlace(pl):\n",
    "    # scrape relevant info for an apartment, return as dict\n",
    "    apt = {'price':pl.select_one(\"span.price\").text, 'loc':pl[\"se:map:point\"], \"id\":pl[\"data-id\"]}\n",
    "    apt[\"addr\"] = pl.select_one(\"div.details-title a\").text\n",
    "    \n",
    "    # does it have a brokers fee?\n",
    "    apt[\"broker_fee\"] = pl.select_one(\"div.banner.no_fee\") is None\n",
    "    \n",
    "    # how far from Columbia?\n",
    "    apt[\"dist\"] = getDistFromColumbia(apt['loc'])\n",
    "    \n",
    "    # sometimes the size is not available\n",
    "    apt_size = pl.select_one(\"span.last_detail_cell\")\n",
    "    if apt_size is not None:\n",
    "        apt[\"size\"] = apt_size.text\n",
    "        \n",
    "    # what neighborhood?\n",
    "    apt[\"nbh\"] = pl(text=re.compile(r' in '))[0]\n",
    "    \n",
    "    # url\n",
    "    apt[\"href\"] = \"http://streeteasy.com\" + pl.select_one(\"div.details-title a\")[\"href\"]\n",
    "    \n",
    "    return apt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping time\n",
    "\n",
    "Now its time to scrape. To get the URL I just went to streetEasy, set the parameters I wanted, and copied that URL to here. Now it probably would have been better to make those all variables which I set here, but for this example they were never going to change, so I'll save that work for the next time I move\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "steasy = \"http://streeteasy.com/for-rent/nyc/price:1000-2000%7Carea:154,148,153,147%7Cbeds%3C1?sort_by=listed_desc\"\n",
    "st = requests.get(steasy)\n",
    "soup = BeautifulSoup(st.text, \"html.parser\")\n",
    "stplaces = soup.select(\"div.item\")\n",
    "\n",
    "places = [getPlace(s) for s in stplaces]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Using email as push notification\n",
    "\n",
    "I would like to get an email when a new place is found, so using smtplib I'll send myself one. Using Yahoo to send the email because I was okay with downgrading the security on that account so it would allow automatically generated sent emails.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import smtplib\n",
    "\n",
    "def sendMail(apt):\n",
    "    # send an email with the apartment information\n",
    "    fromMy = ''\n",
    "    to  = ''\n",
    "    subj='New Apt: ' + apt[\"price\"] + \", Dist: \"+str(apt[\"dist\"])\n",
    "    message_text=str(apt).encode('ascii', 'ignore')\n",
    "    msg = \"From: %s\\nTo: %s\\nSubject: %s\\n\\n%s\" % ( fromMy, to, subj, message_text )\n",
    "\n",
    "    username = str('')  \n",
    "    password = str('')\n",
    "    server = smtplib.SMTP(\"smtp.mail.yahoo.com\",587)\n",
    "    server.ehlo()\n",
    "    server.starttls()\n",
    "    server.login(username,password)\n",
    "    server.sendmail(fromMy, to,msg)\n",
    "    server.quit()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## No duplicates\n",
    "\n",
    "Finally, I don't wan't to get any duplicates, so I'll create a text file with all of the ids of places I've already sent. Only send an email with a place if an id isn't in that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('places.txt', 'r+') as f:\n",
    "    placeIds = f.read()\n",
    "    for p in places:\n",
    "        pSplit = placeIds.split(\",\")\n",
    "        if p[\"id\"] not in pSplit:\n",
    "            print(\"FOUND A NEW SPOT\", p[\"id\"])\n",
    "            sendMail(p)\n",
    "            f.write(p[\"id\"]+\",\")\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update time\n",
    "\n",
    "I also have a text file which writes the last time this file ran, so I can confirm the cron task is working periodically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keep track of last updated time to verify its still running\n",
    "with open(\"time.txt\", 'w+') as wr:\n",
    "    fmt='%Y-%m-%d-%H-%M-%S'\n",
    "    wr.write(datetime.datetime.now().strftime(fmt));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That's it!\n",
    "\n",
    "\n",
    "I've included the python module (find_apt.py) which I used to set up an ubtuntu cron task so this ran automatically. I found this to be a lot of help in my apartment hunt, and I'm hoping it can be of use to someone else."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
